import logging
import os
from datetime import datetime
import pandas_ta as ta
import joblib
import numpy as np
import pandas as pd
import xgboost as xgb
import optuna
import seaborn as sns
import matplotlib
import lightgbm as lgb
import matplotlib.pyplot as plt
from optuna.integration import XGBoostPruningCallback
from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix, \
    classification_report, balanced_accuracy_score
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.preprocessing import RobustScaler, label_binarize
from sklearn.model_selection import cross_validate
from sklearn.metrics import make_scorer
from lightgbm import LGBMClassifier
from model_params import ModelParams
import warnings
warnings.filterwarnings('ignore', category=UserWarning)
from imblearn.over_sampling import ADASYN
from collections import Counter

class IndicatorProcessorAndBreakoutClassifier:

    def __init__(self, symbol_base, symbol_quote, symbol_timeframe, model_title, target_column):
        self.symbol_base = symbol_base
        self.symbol_quote = symbol_quote
        self.symbol_timeframe = symbol_timeframe
        self.model_title = model_title
        self.target_column = target_column
        self.symbol_pair = f'{symbol_base}_{symbol_quote}'
        self.data = None
        self.data_copy = None
        self.features = None
        self.top_features = None
        self.X_val = None
        self.X_train = None
        self.X_test_scaled = None
        self.X_val_scaled = None
        self.X_train_scaled = None
        self.dvalid = None
        self.dtrain = None
        self.xgb_classifier = None
        self.lgbm_classifier = None
        self.column_names = None
        self.X_test = None
        self.logger = None
        self.log_filename = None
        self.scaler = RobustScaler()
        self.log_directory = "./training_logs"
        self.csv_modified_directory = "./csv_modified"
        os.makedirs(self.csv_modified_directory, exist_ok=True)
        # Define the scoring metrics
        self.scoring_metrics = {
            'accuracy': make_scorer(accuracy_score),
            'f1_macro': make_scorer(f1_score, average='macro'),
            'roc_auc_ovr_macro': make_scorer(roc_auc_score, multi_class='ovr', average='macro', needs_proba=True),
            'precision_macro': make_scorer(precision_score, average='macro'),
            'recall_macro': make_scorer(recall_score, average='macro')
        }
        matplotlib.use("TkAgg")

    def setup_logger(self):
        os.makedirs(self.log_directory, exist_ok=True)
        self.log_filename = f"{self.log_directory}/{self.symbol_pair}_{self.symbol_timeframe}_{self.model_title}_scores_{datetime.now().strftime('%Y-%m-%d_%H-%M')}.log"
        self.logger = logging.getLogger(f"{__name__}_{self.symbol_pair}")
        if not self.logger.hasHandlers():
            self.logger.setLevel(logging.INFO)
            log_file_handler = logging.FileHandler(self.log_filename)
            log_file_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s', '%Y-%m-%d %H:%M:%S'))
            self.logger.addHandler(log_file_handler)
            stream_handler = logging.StreamHandler()
            stream_handler.setFormatter(logging.Formatter('%(asctime)s - %(message)s', '%Y-%m-%d %H:%M:%S'))
            self.logger.addHandler(stream_handler)

    def load_csv_data(self):
        self.logger.info(f"{self.symbol_pair} - Loading OHLCV data...")
        self.logger.info(f"{self.symbol_pair} - timeframe: {self.symbol_timeframe} model name: {self.model_title}")
        self.data = pd.read_csv(f'./csv_ohlcv/{self.symbol_pair}_{self.symbol_timeframe}_2015-01-01_now_binance.csv',
                                header=0, names=['timestamp', 'open', 'high', 'low', 'close', 'volume'])
        self.data['timestamp'] = pd.to_datetime(self.data['timestamp'], unit='ms')
        self.data.set_index('timestamp', inplace=True)
        self.logger.info(f"{self.symbol_pair} - OHLCV data loaded.")
        return self.data

    def add_indicators(self):
        self.logger.info(f"{self.symbol_pair} - Adding indicators...")
        self.data.ta.adx(length=20, append=True, fill_method='ffill')
        self.data.ta.macd(fast=18, slow=32, signal=12, append=True, fill_method='ffill')
        self.data.ta.rsi(length=19, append=True, fill_method='ffill')
        self.data.ta.bbands(length=20, append=True, fill_method='ffill')
        self.data.ta.aroon(length=25, append=True, fill_method='ffill')
        self.data.ta.cci(length=24, append=True, fill_method='ffill')
        self.data.ta.obv(length=21, append=True, fill_method='ffill')
        self.data.ta.mfi(length=20, append=True, fill_method='ffill')
        self.data.ta.squeeze(length=20, append=True, lazybear=True, fill_method='ffill')
        self.data.ta.atr(length=21, append=True, fill_method='ffill')
        self.data.ta.ichimoku(length=25, append=True, lookahead='False', fill_method='ffill')
        self.data.ta.trix(length=24, append=True, fill_method='ffill')
        self.data.ta.uo(fast=14, medium=21, slow=29, append=True, fill_method='ffill')
        self.data.ta.ebsw(length=38, append=True, fill_method='ffill')
        self.data.ta.pdist(append=True, fill_method='ffill')

        self.data['EMA_12'] = self.data.ta.ema(length=12)
        self.data['EMA_20'] = self.data.ta.ema(length=20)
        self.data['EMA_50'] = self.data.ta.ema(length=50)
        self.data['EMA_100'] = self.data.ta.ema(length=100)
        self.data['EMA_200'] = self.data.ta.ema(length=200)
        self.data['ema_distance'] = self.data['EMA_12'] - self.data['EMA_20']
        self.data['EMA_50_100_diff'] = self.data['EMA_50'] - self.data['EMA_100']
        self.data['EMA_50_200_diff'] = self.data['EMA_50'] - self.data['EMA_200']
        self.data['EMA_100_200_diff'] = self.data['EMA_100'] - self.data['EMA_200']
        self.data['macd_diff'] = self.data['MACD_18_32_12'] - self.data['MACDs_18_32_12']
        self.data['rsi_20_ma'] = self.data['RSI_19'].rolling(window=18).mean()
        self.data['rsi_diff'] = self.data['RSI_19'] - self.data['rsi_20_ma']
        self.data['ema_30_roc'] = self.data['EMA_20'].pct_change()
        self.data['adx_20_roc'] = self.data['ADX_20'].pct_change()
        self.data['composite_score'] = (self.data['macd_diff'].apply(np.sign) +
                                        self.data['rsi_diff'].apply(np.sign) +
                                        self.data['ema_30_roc'].apply(np.sign) +
                                        self.data['adx_20_roc'].apply(np.sign))
        self.data['cci_rolling_std'] = self.data['CCI_24_0.015'].rolling(window=14).std()
        # Calculate the difference between DMP_20 and DMN_20
        self.data['DMP_DMN_diff'] = self.data['DMP_20'] - self.data['DMN_20']

        # Calculate the ratio between DMP_20 and DMN_20, avoiding division by zero
        self.data['DMP_DMN_ratio'] = np.where(self.data['DMN_20'] != 0, self.data['DMP_20'] / self.data['DMN_20'], 0)

        # Calculate a rolling average for DMP_20 and DMN_20
        self.data['DMP_20_roll_avg'] = self.data['DMP_20'].rolling(window=20).mean()
        self.data['DMN_20_roll_avg'] = self.data['DMN_20'].rolling(window=20).mean()

        # Modify existing features to avoid division by zero
        self.data['rsi_ema_ratio'] = np.where(self.data['EMA_20'] != 0, self.data['RSI_19'] / self.data['EMA_20'], 0)
        self.data['macd_adx_ratio'] = np.where(self.data['ADX_20'] != 0,
                                               self.data['MACD_18_32_12'] / self.data['ADX_20'], 0)

        # Calculate the percentage change between the current price and the price after 21 periods
        self.data['future_price_pct_change'] = (self.data['close'].shift(-1) - self.data['close']) / self.data['close']

        # Set the trend column to 0 (neutral)
        self.data[self.target_column] = 0

        # Calculate the 10 and 30 period EMA
        self.data['EMA_10'] = self.data.ta.ema(length=10).shift(-1)
        self.data['EMA_30'] = self.data.ta.ema(length=30).shift(-1)

        # Create conditions for the uptrend and downtrend
        uptrend_condition = ((self.data['EMA_10'] > self.data['EMA_30']) &
                             (self.data['future_price_pct_change'] > 0.0025))
        downtrend_condition = ((self.data['EMA_10'] < self.data['EMA_30']) &
                               (self.data['future_price_pct_change'] < -0.0025))

        # Assign the trend based on the conditions
        self.data.loc[uptrend_condition, self.target_column] = 1
        self.data.loc[downtrend_condition, self.target_column] = 2
        self.data.drop(['macd_diff', 'rsi_diff', 'ema_30_roc', 'adx_20_roc', 'volume', 'close', 'high', 'low',
                        'SQZ_NO', 'rsi_20_ma', 'DMP_20', 'DMN_20', 'future_price_pct_change', 'EMA_10', 'EMA_30',
                        'MACDs_18_32_12', 'MACDh_18_32_12', 'AROONOSC_25', 'RSI_19', 'ADX_20', 'EMA_12', 'EMA_20',
                        'EMA_50', 'EMA_100', 'EMA_200', 'CCI_24_0.015'],
                       axis=1, inplace=True)

        self.data.dropna(axis=0, inplace=True)
        self.logger.info(f"{self.symbol_pair} - Indicators calculation finished.")

    def load_or_save_data(self):
        def log_trend_counts():
            class_zero_count = (self.data[self.target_column] == 0).sum()
            class_one_count = (self.data[self.target_column] == 1).sum()
            class_two_count = (self.data[self.target_column] == 2).sum()

            self.logger.info(f"{self.symbol_pair} - Number of rows with class 0: {class_zero_count}")
            self.logger.info(f"{self.symbol_pair} - Number of rows with class 1: {class_one_count}")
            self.logger.info(f"{self.symbol_pair} - Number of rows with class 2: {class_two_count}")

        output_path = f'./csv_modified/{self.symbol_pair}_{self.symbol_timeframe}_{self.model_title}.csv'
        if not os.path.isfile(output_path):
            self.add_indicators()
            log_trend_counts()
            self.logger.info(f"{self.symbol_pair} - Saving preprocessed data with indicators to csv file...")
            self.data.to_csv(output_path, index=True)
            self.logger.info(f"{self.symbol_pair} data with indicators saved to csv file.")
        else:
            self.logger.info(f"{self.symbol_pair} - Loading preprocessed data with indicators from csv file...")
            self.data = pd.read_csv(output_path)
            self.data.set_index('timestamp', inplace=True)
            log_trend_counts()

    def perform_optuna_optimization(self):
        lgbm_study = optuna.create_study(pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction="maximize",
                                         study_name="LightGBM Classifier")
        lgbm_study.optimize(self.lgbm_objective, n_trials=50, timeout=500)

        study = optuna.create_study(direction="maximize", study_name="XGBoost Classifier")
        study.optimize(self.xgb_objective, n_trials=50, timeout=500)

        return study, lgbm_study

    def xgb_objective(self, trial):
        xgb_params = ModelParams.get_xgb_params(trial)

        # Initialize cross-validation
        tscv = TimeSeriesSplit(n_splits=10)
        total_score = 0

        for train_index, val_index in tscv.split(self.X_train_scaled):
            X_train, X_val = self.X_train_scaled[train_index], self.X_train_scaled[val_index]
            y_train, y_val = self.y_train.iloc[train_index], self.y_train.iloc[val_index]
            self.dtrain = xgb.DMatrix(X_train, label=y_train)
            self.dvalid = xgb.DMatrix(X_val, label=y_val)
            self.watchlist = [(self.dtrain, 'train'), (self.dvalid, 'eval')]

            pruning_callback = XGBoostPruningCallback(trial, 'eval-mlogloss')

            # Train the model with the current hyperparameters.
            xgb_classifier = xgb.train(xgb_params, self.dtrain, num_boost_round=trial.suggest_int('num_boost_round', 200, 700),
                                       evals=self.watchlist, verbose_eval=1000,
                                       callbacks=[pruning_callback])

            # Make predictions on the validation data.
            y_pred = np.argmax(xgb_classifier.predict(self.dvalid), axis=1)

            # Calculate the balanced accuracy score and add it to the total score
            total_score += balanced_accuracy_score(y_val, y_pred)

        # The objective value is the average of the total scores
        return total_score / tscv.n_splits

    def lgbm_objective(self, trial):
        lgbm_params = ModelParams.get_lgbm_params(trial)
        num_boost_round = trial.suggest_int('num_boost_round', 100, 500)
        tscv = TimeSeriesSplit(n_splits=10)
        scores = []

        for train_index, valid_index in tscv.split(self.X_train_scaled):
            # Create datasets for lightgbm
            lgb_train = lgb.Dataset(self.X_train_scaled[train_index], self.y_train[train_index])
            lgb_eval = lgb.Dataset(self.X_train_scaled[valid_index], self.y_train[valid_index], reference=lgb_train)

            self.lgbm_classifier = lgb.train(
                params=lgbm_params,
                train_set=lgb_train,
                valid_sets=[lgb_eval],
                num_boost_round=num_boost_round,
                callbacks=[
                    optuna.integration.LightGBMPruningCallback(trial, metric='auc_mu')
                ]
            )

            y_pred = self.lgbm_classifier.predict(self.X_train_scaled[valid_index])
            y_pred = np.argmax(y_pred, axis=1)

            # Evaluate on the validation data and append to scores.
            score = accuracy_score(self.y_train[valid_index], y_pred)
            scores.append(score)

        # Return the mean error.
        return np.mean(scores)

    def split_data(self, X=None, y=None, test_size=0.2):
        if X is None:
            X = self.data[self.features]
        if y is None:
            y = self.data[self.target_column]
        return train_test_split(X, y, test_size=test_size, random_state=35, shuffle=False)

    def fit_and_scale_model(self, model, study, model_name):
        self.logger.info(f"{self.symbol_pair} - Fitting and scaling {model_name}...")

        best_trial_params = study.best_trial.params
        n_estimators = best_trial_params.pop('num_boost_round', 100)

        model = model(n_estimators=n_estimators, **best_trial_params)

        # Fit the scaler on the entire DataFrame with all features
        self.scaler.fit(self.X_train)

        self.X_train_scaled = self.scaler.transform(self.X_train)
        self.X_val_scaled = self.scaler.transform(self.X_val)
        self.X_test_scaled = self.scaler.transform(self.X_test)

        X_train_final = np.concatenate((self.X_train_scaled, self.X_val_scaled), axis=0)
        y_train_final = np.concatenate((self.y_train, self.y_val), axis=0)

        self.logger.info(f"{self.symbol_pair} - Training final {model_name}  model...")
        model.fit(X_train_final, y_train_final)

        # Log results and feature importances
        self.log_results(study, model_name)
        self.log_feature_importances(model, model_name)

        return model

    def train_xgboost(self, xgb_study):
        self.xgb_classifier = self.fit_and_scale_model(xgb.XGBClassifier, xgb_study, "XGBoost")

    def train_lightgbm(self, lgbm_study):
        self.lgbm_classifier = self.fit_and_scale_model(LGBMClassifier, lgbm_study, "LightGBM")

    def set_features_and_targets(self):
        self.logger.info(f"{self.symbol_pair} - Setting features and target variables for ML models...")
        self.features = self.data.columns[:].drop([self.target_column])

    def split_dataset(self):
        self.logger.info(f"{self.symbol_pair} - Preparing for training the xgboost model...")
        self.X_train, self.X_test, self.y_train, self.y_test = self.split_data()
        self.X_train, self.X_val, self.y_train, self.y_val = self.split_data(test_size=0.2, X=self.X_train,
                                                                             y=self.y_train)

        # Resample the training data using ADASYN
        self.logger.info(f"{self.symbol_pair} - Oversampling the minority class in the training data...")
        adasyn = ADASYN()
        self.X_train, self.y_train = adasyn.fit_resample(self.X_train, self.y_train)
        # Count the class distribution after oversampling
        counter = Counter(self.y_train)

        self.logger.info(f"{self.symbol_pair} - Class 0 distribution after oversampling: {counter[0]}")
        self.logger.info(f"{self.symbol_pair} - Class 1 distribution after oversampling: {counter[1]}")
        self.logger.info(f"{self.symbol_pair} - Class 2 distribution after oversampling: {counter[2]}")

        self.log_shapes()

    def log_shapes(self):
        self.logger.debug(f"X_train shape: {self.X_train.shape}")
        self.logger.debug(f"X_test shape: {self.X_test.shape}")
        self.logger.debug(f"y_train shape: {self.y_train.shape}")
        self.logger.debug(f"y_test shape: {self.y_test.shape}")

    def scale_features(self):
        # Apply Scaler to the features
        self.logger.info(f"{self.symbol_pair} - Applying {self.scaler} to the features...")
        self.X_train_scaled = self.scaler.fit_transform(self.X_train)
        self.X_val_scaled = self.scaler.transform(self.X_val)
        self.X_test_scaled = self.scaler.transform(self.X_test)

    def hyperparameter_tuning(self):
        # Optuna hyperparameter tuning for XGBoost and LightGBM
        self.logger.info(f"{self.symbol_pair} - Starting hyperparameter tuning...")
        xgb_study, lgbm_study = self.perform_optuna_optimization()
        return xgb_study, lgbm_study

    def train_model(self):
        self.set_features_and_targets()
        self.split_dataset()
        self.scale_features()
        xgb_study, lgbm_study = self.hyperparameter_tuning()
        self.train_xgboost(xgb_study)
        self.train_lightgbm(lgbm_study)

    def log_results(self, study, model_name):
        self.logger.info(f"Optuna optimization for {model_name} completed.")
        self.logger.info(f"pair: {self.symbol_pair} timeframe: {self.symbol_timeframe}")
        self.logger.info(f"model title: {self.model_title}")
        self.logger.info(f"features: {self.features}")
        self.logger.info("Best parameters found: %s", study.best_params)
        self.logger.info("Best value (score) found: %s", study.best_value)

    def log_feature_importances(self, model, model_name):
        importances = model.feature_importances_
        sorted_features = sorted(zip(self.features, importances), key=lambda x: x[1], reverse=True)
        self.logger.info(f"\n{model_name} Feature importances:")
        for feature, importance in sorted_features:
            self.logger.info("%s: %s", feature, importance)

    def log_average_scores(self, scores):
        self.logger.info(f"Average Accuracy: {np.mean(scores['test_accuracy']):.4f}")
        self.logger.info(f"Average F1-score: {np.mean(scores['test_f1_macro']):.4f}")
        self.logger.info(f"Average AUC: {np.mean(scores['test_roc_auc_ovr_macro']):.4f}")
        self.logger.info(f"Average Precision: {np.mean(scores['test_precision_macro']):.4f}")
        self.logger.info(f"Average Recall: {np.mean(scores['test_recall_macro']):.4f}")

    def evaluate_model(self):
        # Use TimeSeriesSplit for evaluation consistency
        time_series_cv = TimeSeriesSplit(n_splits=5)

        # Start model evaluation and score calculation
        self.logger.info(f"{self.symbol_pair} - Starting model evaluation and score calculation...")

        # Perform cross-validation
        scores = cross_validate(self.xgb_classifier, self.X_train_scaled, self.y_train, cv=time_series_cv,
                                scoring=self.scoring_metrics, return_train_score=False)

        # Log average scores
        self.log_average_scores(scores)

    def evaluate_test_set(self):
        self.logger.info("Evaluating the model on the test set...")
        self.data_copy = self.data.copy()
        # XGBoost
        y_pred_test_xgb = self.xgb_classifier.predict(self.X_test_scaled)
        y_pred_proba_test_xgb = self.xgb_classifier.predict_proba(self.X_test_scaled)
        # LightGBM
        y_pred_test_lgbm = self.lgbm_classifier.predict(self.X_test_scaled)

        # Evaluation metrics
        for model_name, y_pred, y_pred_proba in zip(['XGBoost', 'LightGBM'], [y_pred_test_xgb, y_pred_test_lgbm],
                                                    [y_pred_proba_test_xgb, None]):
            test_accuracy = accuracy_score(self.y_test, y_pred)
            test_f1 = f1_score(self.y_test, y_pred, average='macro')
            if y_pred_proba is not None:
                if model_name == 'XGBoost':
                    y_test_binarized = label_binarize(self.y_test, classes=[0, 1, 2])
                    test_auc = roc_auc_score(y_test_binarized, y_pred_proba, multi_class='ovr', average='macro')
                else:
                    test_auc = 'N/A'
            else:
                test_auc = 'N/A'
            test_precision = precision_score(self.y_test, y_pred, average='macro')
            test_recall = recall_score(self.y_test, y_pred, average='macro')

            test_conf_matrix = confusion_matrix(self.y_test, y_pred)
            test_class_report = classification_report(self.y_test, y_pred)

            self.logger.info(f"{model_name} - \nTest set Confusion Matrix:\n{test_conf_matrix}")
            self.logger.info(f"{model_name} - \nTest set Classification Report:\n{test_class_report}")
            self.logger.info(f"{model_name} - Test set Accuracy: {test_accuracy:.4f}")
            self.logger.info(f"{model_name} - Test set F1-score: {test_f1:.4f}")
            self.logger.info(f"{model_name} - Test set AUC: {test_auc}")
            self.logger.info(f"{model_name} - Test set Precision: {test_precision:.4f}")
            self.logger.info(f"{model_name} - Test set Recall: {test_recall:.4f}")

    def eda(self):
        # Combine train and test data for EDA
        combined_data = pd.concat([self.X_train, self.X_test])

        # Add the target variable
        combined_data[self.target_column] = pd.concat([self.y_train, self.y_test])

        # Distribution of the target variable
        plt.figure(figsize=(10, 6))
        sns.countplot(x=self.target_column, data=combined_data)
        plt.title('Distribution of Trend')
        plt.savefig('trend_distribution.png')

        # Correlation matrix of features
        plt.figure(figsize=(10, 10))
        corr = combined_data.corr()
        sns.heatmap(corr, cmap='coolwarm', annot=True)
        plt.title('Correlation Matrix of Features')
        plt.savefig('correlation_matrix.png')

    def plot_predictions(self):
        # Add predictions to original unscaled test data
        predictions = self.xgb_classifier.predict(self.X_test_scaled)

        # Make sure that the X_test and y_test DataFrames share the same index
        assert np.array_equal(self.X_test.index, self.y_test.index), "Indices of X_test and y_test do not match."

        # Create a DataFrame to hold the actual and predicted values
        results = pd.DataFrame({
            'Timestamp': self.X_test.index,  # Assuming X_test contains 'timestamp' as index
            'Actual': self.y_test,
            'Predicted': predictions
        }, index=self.X_test.index)

        # Scatter plot of actual vs predicted
        plt.figure(figsize=(10, 6))
        plt.scatter(results['Timestamp'], results['Actual'], label='Actual')
        plt.scatter(results['Timestamp'], results['Predicted'], label='Predicted')
        plt.xlabel('Timestamp')
        plt.ylabel('Value')
        plt.title('Actual vs Predicted')
        plt.legend()
        plt.show()

    def save_model(self):
        self.logger.info(f"{self.symbol_pair} - Saving models...")
        # Save the scaler
        scaler_path = f'./models/{self.symbol_base}_{self.symbol_quote}/' \
                      f'{self.symbol_base}_{self.symbol_quote}_' \
                      f'{self.symbol_timeframe}_{self.model_title}_scaler.joblib'
        directory = os.path.dirname(scaler_path)
        os.makedirs(directory, exist_ok=True)
        joblib.dump(self.scaler, scaler_path)
        self.logger.info(f"{self.symbol_pair} - Scaler object saved...")

        # Save XGBoost model
        best_model_path_xgb = f'./models/{self.symbol_base}_{self.symbol_quote}/' \
                              f'{self.symbol_base}_{self.symbol_quote}_' \
                              f'{self.symbol_timeframe}_{self.model_title}_xgboost.model'
        directory = os.path.dirname(best_model_path_xgb)
        os.makedirs(directory, exist_ok=True)
        self.xgb_classifier.save_model(best_model_path_xgb)
        self.logger.info(f"{self.symbol_pair} - XGBoost model saved...")

        # Save LightGBM model
        best_model_path_lgbm = f'./models/{self.symbol_base}_{self.symbol_quote}/' \
                               f'{self.symbol_base}_{self.symbol_quote}_' \
                               f'{self.symbol_timeframe}_{self.model_title}_lightgbm.model'
        directory = os.path.dirname(best_model_path_lgbm)
        os.makedirs(directory, exist_ok=True)
        joblib.dump(self.lgbm_classifier, best_model_path_lgbm)
        self.logger.info(f"{self.symbol_pair} - LightGBM model saved...")

        self.logger.info(f"{self.symbol_pair} - Training finished!")


if __name__ == '__main__':
    # base_symbols = ['ETH', 'BTC', 'ADA', 'ATOM', 'AVAX', 'DOT', 'ETC', 'LINK', 'LTC', 'MATIC', 'SOL', 'XRP']
    base_symbols = ['ETH', 'BTC']
    quote_symbols = ['USDT']
    symbol_timeframe = '15m'
    model_title = 'pct_change_00025_ema_v1'
    target_column = 'trend'

    for base_symbol in base_symbols:
        for quote_symbol in quote_symbols:
            symbol = f"{base_symbol}/{quote_symbol}"
            processor_and_classifier = IndicatorProcessorAndBreakoutClassifier(base_symbol, quote_symbol,
                                                                               symbol_timeframe, model_title, target_column)
            # Check if the XGBoost model file already exists
            model_path_xgb = f'./models/{base_symbol}_{quote_symbol}/' \
                             f'{base_symbol}_{quote_symbol}_' \
                             f'{symbol_timeframe}_{model_title}_xgboost.model'

            # Check if the LightGBM model file already exists
            model_path_lgbm = f'./models/{base_symbol}_{quote_symbol}/' \
                              f'{base_symbol}_{quote_symbol}_' \
                              f'{symbol_timeframe}_{model_title}_lightgbm.model'

            processor_and_classifier.setup_logger()

            if not os.path.exists(model_path_xgb) or not os.path.exists(model_path_lgbm):
                processor_and_classifier.load_csv_data()
                processor_and_classifier.load_or_save_data()
                processor_and_classifier.train_model()
                processor_and_classifier.evaluate_test_set()
                # processor_and_classifier.plot_predictions()
                processor_and_classifier.save_model()
            else:
                print(f"{symbol} - Model files for both XGBoost and LightGBM already exist, skipping training.")

